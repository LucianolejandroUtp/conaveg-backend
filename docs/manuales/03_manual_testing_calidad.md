# üß™ MANUAL 3: GU√çA DE TESTING Y CALIDAD - SISTEMA CONA

## üìã **INFORMACI√ìN DEL DOCUMENTO**

**Fecha de Creaci√≥n**: 21 de Julio de 2025  
**Proyecto**: Sistema CONA (Gesti√≥n CONAVEG)  
**Audiencia**: QA, Desarrolladores, DevOps  
**Nivel**: Intermedio - Avanzado  
**Tiempo Estimado**: 2-4 horas (estudio y pr√°ctica)  
**√öltima Actualizaci√≥n**: 21 de Julio de 2025  

---

## üéØ **OBJETIVOS DE APRENDIZAJE**

Al finalizar este manual, ser√°s capaz de:
- ‚úÖ Comprender la estrategia de testing del Sistema CONA.
- ‚úÖ Ejecutar y escribir tests unitarios y de integraci√≥n.
- ‚úÖ Realizar tests de performance y carga.
- ‚úÖ Aplicar procedimientos de testing manual para funcionalidades cr√≠ticas.
- ‚úÖ Utilizar las herramientas de testing y automatizaci√≥n del proyecto.
- ‚úÖ Interpretar m√©tricas de calidad y cobertura.
- ‚úÖ Entender el flujo de CI/CD y los pipelines de testing.

---

## üìã **REQUISITOS PREVIOS**

### **Conocimientos Necesarios**:
- Conceptos de testing de software (unitario, integraci√≥n, performance).
- Conocimientos b√°sicos de Java, Spring Boot y JUnit.
- Familiaridad con Maven y la l√≠nea de comandos.
- Experiencia con herramientas como Postman o cURL.

### **Herramientas Requeridas**:
- Sistema CONA instalado y funcionando (ver Manual 1).
- JDK 21, Maven 3.8+.
- IDE de desarrollo (IntelliJ, VS Code, Eclipse).
- Cliente de base de datos (DBeaver, HeidiSQL).

---

## üéØ **ESTRATEGIA DE TESTING DEL PROYECTO**

La estrategia de testing del Sistema CONA se basa en un enfoque de m√∫ltiples capas para garantizar la calidad, seguridad y rendimiento del software.

### **Pir√°mide de Testing**:
```
      /‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\
     /  Manual \
    /‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\
   / Performance \
  /‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\
 /   Integraci√≥n   \
/‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\
/      Unitarios      \
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

1.  **Tests Unitarios (Base)**: Pruebas r√°pidas y aisladas que validan componentes individuales (clases, m√©todos) en la capa de servicio y repositorios. Son la base de la pir√°mide y se ejecutan con cada cambio.
2.  **Tests de Integraci√≥n (Medio)**: Verifican la interacci√≥n entre diferentes componentes, como controllers, services y la base de datos (simulada o en memoria). Aseguran que las capas del sistema funcionen juntas correctamente.
3.  **Tests de Performance y Carga (Pico)**: Eval√∫an el comportamiento del sistema bajo estr√©s, midiendo tiempos de respuesta, uso de memoria y estabilidad. Crucial para funcionalidades sensibles como el cifrado BCrypt.
4.  **Testing Manual (Pico)**: Procedimientos guiados para verificar flujos de usuario complejos y funcionalidades cr√≠ticas de seguridad que son dif√≠ciles de automatizar completamente.

### **Enfoque de Calidad**:
- **Prevenci√≥n sobre Detecci√≥n**: Escribir c√≥digo de calidad y tests desde el inicio.
- **Automatizaci√≥n Primero**: Automatizar todos los tests repetibles.
- **Seguridad por Dise√±o**: Integrar el testing de seguridad en todo el ciclo de vida.
- **Cobertura Significativa**: Enfocarse en cubrir la l√≥gica de negocio cr√≠tica en lugar de solo buscar un alto porcentaje.

---

## üß™ **TESTS UNITARIOS Y DE INTEGRACI√ìN**

El proyecto utiliza **JUnit 5**, **Spring Test** y **Mockito** para la implementaci√≥n de tests.

### **Estructura de Tests**:
- **Ubicaci√≥n**: `src/test/java/com/conaveg/cona/`
- **Nomenclatura**: `[NombreClase]Test.java` para tests unitarios y `[NombreClase]IntegrationTest.java` para tests de integraci√≥n.

### **Tests Unitarios (Services y Repositories)**:
Se centran en la l√≥gica de negocio. Se usan Mocks para aislar las dependencias.

**Ejemplo de Test para un Servicio (`UserServiceTest.java`)**:
```java
@ExtendWith(MockitoExtension.class)
class UserServiceTest {

    @Mock
    private UserRepository userRepository;

    @Mock
    private BCryptPasswordEncoder passwordEncoder;

    @InjectMocks
    private UserServiceImpl userService;

    @Test
    void createUser_WithValidData_ShouldReturnUser() {
        // Given (Arrange)
        UserDTO userDTO = new UserDTO();
        userDTO.setEmail("test@test.com");
        userDTO.setPassword("password123");

        when(passwordEncoder.encode("password123")).thenReturn("encodedPassword");
        when(userRepository.save(any(User.class))).thenAnswer(i -> i.getArgument(0));

        // When (Act)
        User createdUser = userService.createUser(userDTO);

        // Then (Assert)
        assertNotNull(createdUser);
        assertEquals("test@test.com", createdUser.getEmail());
        assertEquals("encodedPassword", createdUser.getPassword());
        verify(userRepository, times(1)).save(any(User.class));
    }
}
```

### **Tests de Integraci√≥n (Controllers)**:
Se utiliza `@WebMvcTest` para probar los controllers en un contexto de Spring MVC, pero sin levantar el servidor completo. El servicio se simula con `@MockitoBean`.

**Ejemplo de Test para un Controller (`InventarioControllerIntegrationTest.java`)**:
```java
@WebMvcTest(InventarioController.class)
class InventarioControllerIntegrationTest {

    @Autowired
    private MockMvc mockMvc;

    @MockitoBean
    private InventarioService inventarioService;

    @Autowired
    private ObjectMapper objectMapper;

    @Test
    void getInventarioById_WithValidId_ShouldReturnInventario() throws Exception {
        // Given
        InventarioDTO inventarioDTO = new InventarioDTO();
        inventarioDTO.setId(1L);
        inventarioDTO.setNombre("Laptop Dell");
        when(inventarioService.getInventarioById(1L)).thenReturn(inventarioDTO);

        // When & Then
        mockMvc.perform(get("/api/inventario/1"))
                .andExpect(status().isOk())
                .andExpect(content().contentType(MediaType.APPLICATION_JSON))
                .andExpect(jsonPath("$.id", is(1)))
                .andExpect(jsonPath("$.nombre", is("Laptop Dell")));

        verify(inventarioService, times(1)).getInventarioById(1L);
    }
}
```

### **Ejecuci√≥n de Tests**:
```bash
# Ejecutar todos los tests del proyecto
mvn test

# Ejecutar una clase de test espec√≠fica
mvn test -Dtest=InventarioControllerIntegrationTest

# Ejecutar un m√©todo de test espec√≠fico
mvn test -Dtest=InventarioControllerIntegrationTest#getInventarioById_WithValidId_ShouldReturnInventario
```

---

## üöÄ **TESTS DE PERFORMANCE Y CARGA (BCRYPT)**

La seguridad es cr√≠tica, pero tambi√©n el rendimiento. Se han creado tests espec√≠ficos para evaluar el impacto de BCrypt bajo carga.

### **Estructura de Tests de Performance**:
- **Ubicaci√≥n**: `src/test/java/com/conaveg/cona/performance/`
- **Configuraci√≥n**: `src/test/resources/application-loadtest.properties`

### **Tipos de Tests de Performance**:
1.  **`BCryptLoadTest`**: Creaci√≥n concurrente de usuarios para medir el rendimiento del cifrado.
2.  **`PasswordValidationLoadTest`**: Validaci√≥n masiva de contrase√±as para medir el rendimiento de la verificaci√≥n.
3.  **`BCryptMemoryStabilityTest`**: Monitorea el uso de memoria durante operaciones prolongadas para detectar fugas.
4.  **`BCryptStressTest`**: Eval√∫a el comportamiento del sistema bajo carga extrema.

### **C√≥mo Ejecutar los Tests de Performance**:
```bash
# Ejecutar la suite completa de performance
mvn test -Dtest=BCryptPerformanceSuite

# Ejecutar un test de carga individual
mvn test -Dtest=BCryptLoadTest
```

### **M√©tricas Clave (Resultados de `PERFORMANCE_METRICS.md`)**:
| M√©trica | Valor Objetivo | Valor Medido | Estado |
|---|---|---|---|
| Tiempo de cifrado BCrypt | < 2000ms | 100-500ms | ‚úÖ Excelente |
| Tiempo de validaci√≥n | < 2000ms | 500-1000ms | ‚úÖ Bueno |
| Throughput concurrente | > 5 ops/seg | 10-20 ops/seg | ‚úÖ Excelente |
| Uso de memoria estable | < 100MB variaci√≥n | < 50MB | ‚úÖ Excelente |
| Tasa de √©xito bajo estr√©s | > 90% | > 95% | ‚úÖ Excelente |

Para m√°s detalles, consulte la `docs/Performance_Testing_Guide.md`.

---

## üë®‚Äçüíª **TESTING MANUAL DE FUNCIONALIDADES**

Para flujos complejos y validaci√≥n de seguridad, el testing manual es esencial. La gu√≠a completa se encuentra en `docs/testing/Manual_Testing_Guide.md`.

### **Funcionalidades Cubiertas**:
- **Sistema de Recuperaci√≥n de Contrase√±as**:
    - Solicitar recuperaci√≥n.
    - Validar token (incluyendo expiraci√≥n y uso).
    - Resetear la contrase√±a.
- **Rate Limiting**:
    - Bloqueo por IP tras m√∫ltiples intentos fallidos.
    - Bloqueo por email.
    - Verificaci√≥n de desbloqueo autom√°tico.
- **Auditor√≠a de Seguridad**:
    - Verificaci√≥n de logs de eventos de seguridad (login, logout, cambios de contrase√±a).
- **Tareas Programadas**:
    - Limpieza de tokens expirados.
    - Mantenimiento de logs.

### **Ejemplo de Procedimiento (Solicitar Recuperaci√≥n)**:
1.  **Acci√≥n**: Enviar un request `POST` a `/api/auth/forgot-password` con un email existente.
2.  **Verificaci√≥n**:
    - La API debe responder con un mensaje de √©xito.
    - Se debe crear un token en la tabla `password_reset_tokens` de la base de datos.
    - Se debe registrar un evento `PASSWORD_RESET_REQUESTED` en los logs.

---

## üõ†Ô∏è **HERRAMIENTAS DE TESTING Y AUTOMATIZACI√ìN**

### **Frameworks y Librer√≠as**:
- **JUnit 5**: Framework principal para tests en Java.
- **Spring Test**: Soporte para testing en aplicaciones Spring.
- **Mockito**: Para crear objetos simulados (mocks).
- **AssertJ**: Para aserciones fluidas y legibles.
- **Hamcrest**: Matchers para `MockMvc`.
- **Maven**: Para la gesti√≥n de dependencias y ejecuci√≥n de tests.

### **Herramientas Externas**:
- **Postman / Insomnia / cURL**: Para testing manual de APIs REST.
- **Cliente de Base de Datos**: Para verificar el estado de los datos.

### **Automatizaci√≥n (Scripts)**:
El proyecto incluye scripts de verificaci√≥n en `docs/testing/scripts/` para automatizar health checks.

**Ejemplo de uso del script maestro**:
```bash
# Navegar al directorio de scripts
cd docs/testing/scripts

# Dar permisos de ejecuci√≥n
chmod +x *.sh

# Ejecutar la verificaci√≥n completa
./master_verification.sh
```
Este script ejecuta una serie de verificaciones, incluyendo:
- Autenticaci√≥n.
- Rate limiting.
- Conexi√≥n a la base de datos.

---

## üìä **M√âTRICAS DE CALIDAD Y COBERTURA**

### **Cobertura de C√≥digo**:
El objetivo no es el 100%, sino una cobertura significativa de la l√≥gica de negocio cr√≠tica. Se utilizan herramientas como **JaCoCo** para medirla.

```bash
# Generar reporte de cobertura con Maven
mvn clean verify
```
El reporte se encontrar√° en `target/site/jacoco/index.html`.

### **M√©tricas de Calidad (de `docs/testing/README.md`)**:
- **Cobertura de Endpoints de Autenticaci√≥n**: 100%
- **Cobertura de Rate Limiting**: 100%
- **Tests Cr√≠ticos Automatizados**: 85%
- **Health Checks Automatizados**: 100%

---

## üîÑ **CI/CD Y PIPELINES DE TESTING**

Aunque no hay un archivo de pipeline (ej. `Jenkinsfile`) en el repositorio, el flujo de Integraci√≥n Continua y Despliegue Continuo (CI/CD) se basa en los siguientes pasos conceptuales, que pueden ser implementados en cualquier herramienta de CI/CD (Jenkins, GitLab CI, GitHub Actions).

### **Fases del Pipeline**:

1.  **Checkout**:
    - Clona el repositorio de Git.

2.  **Build & Test**:
    - **Compilar**: `mvn clean compile`
    - **Ejecutar Tests Unitarios y de Integraci√≥n**: `mvn test`
    - **An√°lisis de Calidad**: Ejecutar an√°lisis de SonarQube (si est√° configurado).
    - **Generar Reporte de Cobertura**: `mvn verify` (con JaCoCo).

3.  **Package**:
    - **Empaquetar la Aplicaci√≥n**: `mvn clean package -DskipTests`
    - El resultado es un archivo JAR ejecutable en `target/`.

4.  **Deploy to Staging**:
    - Despliega el JAR en un entorno de pre-producci√≥n (staging).

5.  **Verification & Load Testing**:
    - **Ejecutar Scripts de Verificaci√≥n**: `master_verification.sh` contra el entorno de staging.
    - **Ejecutar Tests de Performance**: `mvn test -Dtest=BCryptPerformanceSuite` (opcional, puede ser una tarea programada).

6.  **Deploy to Production (Manual/Autom√°tico)**:
    - Si todas las fases anteriores son exitosas, se promueve el artefacto a producci√≥n.

---

## üìû **SOPORTE Y RECURSOS ADICIONALES**

### **Documentaci√≥n Relevante**:
- üìñ [Manual de Testing Manual](docs/testing/Manual_Testing_Guide.md)
- üöÄ [Gu√≠a de Tests de Performance](docs/Performance_Testing_Guide.md)
- üîß [Documentaci√≥n de Scripts de Verificaci√≥n](docs/testing/Verification_Scripts.md)

### **Canales de Soporte**:
- üìß **Email**: qa-team@conaveg.com
- üí¨ **Slack**: #cona-testing

---

**üìÖ Fecha de Creaci√≥n**: 21 de Julio de 2025  
**üë®‚Äçüíª Responsable**: Equipo de Calidad CONA  
**üìã Estado**: Manual Completo y Validado  
**üîÑ Pr√≥xima Revisi√≥n**: 21 de Agosto de 2025
